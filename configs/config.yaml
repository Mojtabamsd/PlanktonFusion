base:
  cpu: False
  all_gpu: False
  gpu_index: 0


sampling:
  uvp_type: 'UVP6'          # choose 'UVP5' or 'UVP6' or 'BOTH' merge both uvp
  path_uvp5: 'D:\mojmas\files\data\UVP5_images_dataset'
  path_uvp6: 'D:\mojmas\files\data\UVP6Net'
  path_uvp6_csv: False  # load from a csv file dir i.e. 'dir' otherwise False
  path_output: 'D:\mojmas\files\data\result_sampling'
  num_class: 13             # choose 13 or 23 classes
  sampling_method: 'stratified'  # choose 'fixed' or 'uniform' or 'stratified'
  sampling_percent_uvp5: 0.9
  sampling_percent_uvp6: 0.9
  target_size: None  # default is better to set None for not loosing aspect ratio
  test_dataset_sampling: 'stratified' # choose 'fixed' or 'uniform'(percent) or 'stratified',  it created [test_percent] of dataset for testing algorithm
  test_percent_uvp5: 0.1  #for 'stratified' it should be between 0.0 and 1.0 and represent the proportion of the dataset to include in the test split.
  test_percent_uvp6: 0.1
  create_folder: False  # if True it will create sub-folders with class naming


sampling_syn:
  path_syn: 'D:\mojmas\files\Projects\WP14\data\UVP_images'
  uvp_type: 'UVP6'          # choose 'UVP6'
  path_uvp6: 'D:\mojmas\files\data\UVP6Net'
  path_uvp6_csv: False  # load from a csv file dir i.e. 'dir' otherwise False
  labels_included: ['Amphipoda', 'Swima', 'Coelodendridae', 'Annelida', 'Creseis']
  path_output: 'D:\mojmas\files\data\result_sampling'
  sampling_method: 'stratified'  # choose 'fixed' or 'uniform' or 'stratified'
  sampling_percent_uvp6: 0.9
  target_size: [227, 227]  #image target size
  test_dataset_sampling: 'stratified' # choose 'fixed' or 'uniform'(percent) or 'stratified',  it created [test_percent] of dataset for testing algorithm
  test_percent_uvp6: 0.1
  create_folder: False  # if True it will create sub-folders with class naming


training:
  architecture_type: 'resnet18' # choose 'resnet18', 'resnet34', 'resnet50' or 'resnext50'
  batch_size: 256
  num_workers: 10
  gray: True
  target_size: [128, 128]  #image target size
  aug_mode: 1 # 1 normal, 2 massive
  padding: True # pad image to preserve aspect ratio
  pre_train: False # True or False
  learning_rate: 0.001
  num_epoch: 60
  save_model_every_n_epoch: 50
  loss: 'cross_entropy_weight' # choose 'cross_entropy' or 'cross_entropy_weight' or 'focal' or 'LACE'
#  path_pretrain: 'D:\mojmas\files\data\result_sampling\training20231123092750' # if False training from scratch
  path_pretrain: False # if False training from scratch


training_contrastive:
  dataset: 'imagenet' # choose uvp or imagenet
  architecture_type: 'resnet50' # choose 'resnet18', 'resnet34', 'resnet50' or 'resnext50'
  batch_size: 256
  accumulation_steps: 4  #for mini batch size --- the training performs like batch_size // accumulation_steps i.e. 256=64*4
  num_workers: 15
  gray: False
  target_size: [128, 128]  #image target size
  padding: True # pad image to preserve aspect ratio
  pre_train: None # True or None
  learning_rate: 0.1
  momentum: 0.9 # momentum of SGD solver (default: 0.9)
  weight_decay: 0.0002 #weight decay (default: 2e-4)
  schedule: [160, 180] # learning rate schedule (when to drop lr by 10x)')
  num_epoch: 90
  warmup_epochs: 5 # warmup epochs
  save_model_every_n_epoch: 50
  loss: 'procom' # choose 'proco' or 'procom'
  max_modes: 5
  feat_dim: 1024 # feature dimension of mlp head
  temp: 0.07  # scalar temperature for contrastive learning
  use_norm: true # cosine classifier.
#  path_pretrain: 'D:\mojmas\files\data\result_sampling\training_contrastive20240813152329' # if False training from scratch
  path_pretrain: False # if False training from scratch


prediction:
  path_model: 'D:\mojmas\files\data\result_sampling\training20231123092750'
  batch_size: 2


prediction_auto:
  path_model_auto: 'D:\mojmas\files\data\result_sampling\autoencoder_training20240219162906'
  path_model_class: 'D:\mojmas\files\data\result_sampling\training20231123092750'
  architecture_type1: 'resnet18_autoencoder' # choose autoencoder path 'conv_autoencoder' or 'resnet18_autoencoder'
  architecture_type2: 'resnet18' # choose classification model path 'resnet18'
  latent_dim: 64
  batch_size: 192


autoencoder:
  architecture_type: 'resnet18' # choose 'conv_autoencoder' or 'resnet18' or 'resnet18_autoencoder'
  latent_dim: 55
  batch_size: 32
  gray: True
  learning_rate: 0.001
  num_epoch: 100
  save_model_every_n_epoch: 20
  loss: 'cross_entropy_weight' # choose 'cross_entropy' or 'cross_entropy_weight' or 'focal' or 'mse' or or 'w_mse', quantile' or 'per_rec'
  path_pretrain: 'D:\mojmas\files\data\result_sampling\autoencoder_training20231207125558' # if False training from scratch


ssl:
  architecture_type: 'simclr' # choose 'simclr'
  temperature: 0.07
  latent_dim: 16
  batch_size: 64
  gray: True
  learning_rate: 0.001
  num_epoch: 100
  save_model_every_n_epoch: 20
  loss: 'cross_entropy' # choose 'cross_entropy'


classifier:
  path_model: 'D:\mojmas\files\data\result_sampling\autoencoder_training20240219162906'  # if it's not NN write None
  feature_type: 'resnet18_autoencoder'  # choose 'conv_autoencoder' or 'uvpec' or 'resnet18' or or 'resnet18_autoencoder'
  batch_size: 192
  classifier_type: 'xgboost' # choose 'svm' or 'xgboost' or 'isf'


memory:
  visual_embedded_model: 'D:\mojmas\files\data\result_sampling\autoencoder_training20240112130643'  #path of embedding model
  loss: 'cross_entropy' # choose 'cross_entropy' or 'cross_entropy_weight' or 'focal' or 'LACE'
  k: 100  #number of k-NN
  batch_size: 64
  num_epoch: 100


